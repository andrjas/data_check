---
kind: pipeline
name: oracle

platform:
  os: linux
  arch: arm64

steps:
- commands:
  - cp -rn example/checks test/int_test/oracle
  - cp -rn example/load_data test/int_test/oracle
  - cp -rn example/run_sql test/int_test/oracle
  - cp -rn example/lookups test/int_test/oracle
  - cp -rn example/fake test/int_test/oracle
  - poetry install -E oracle
  - cd test/int_test/oracle
  - poetry run data_check ping --wait --timeout 60 --retry 5
  - rm -f checks/pipelines/fake_data/main.simple_fake_table.csv
  - rm -f checks/pipelines/fake_data/main.simple_fake_table_2.csv
  - rm -f checks/generated/data_with_hash.csv
  - rm -f test.db
  - poetry run data_check sql --workers 1 --files prepare
  - poetry run pytest ../test_int_tests.py
  - poetry run pytest ../../../test/database
  environment:
    DB_CONNECTION:
      from_secret: ORACLE_CONNECTION
    DB_PASSWORD:
      from_secret: ORACLE_PASSWORD
    DB_USER:
      from_secret: ORACLE_USER
    LANG: en_US.utf-8
    LC_ALL: en_US.utf-8
    NLS_LANG: .utf8
    TNS_ADMIN: /app/network/admin
  image: local/poetry_oracle
  name: data_check
  pull: if-not-exists
  volumes:
  - name: cache
    path: /root/.cache
  - name: wallet
    path: /app/network/admin
type: docker
volumes:
- host:
    path: /tmp/data_check_cache
  name: cache
- host:
    path: /home/data_check/wallet
  name: wallet
---
kind: pipeline
name: sqlite

platform:
  os: linux
  arch: arm64

steps:
- commands:
  - cp -rn example/checks test/int_test/sqlite
  - cp -rn example/load_data test/int_test/sqlite
  - cp -rn example/run_sql test/int_test/sqlite
  - cp -rn example/lookups test/int_test/sqlite
  - cp -rn example/fake test/int_test/sqlite
  - poetry install
  - cd test/int_test/sqlite
  - poetry run data_check ping --wait --timeout 60 --retry 5
  - rm -f checks/pipelines/fake_data/main.simple_fake_table.csv
  - rm -f checks/pipelines/fake_data/main.simple_fake_table_2.csv
  - rm -f checks/generated/data_with_hash.csv
  - rm -f test.db
  - poetry run data_check sql --workers 1 --files prepare
  - poetry run pytest ../test_int_tests.py
  - poetry run pytest ../../../test/database
  environment: {}
  image: local/poetry:3.8
  name: data_check
  pull: if-not-exists
  volumes:
  - name: cache
    path: /root/.cache
type: docker
volumes:
- host:
    path: /tmp/data_check_cache
  name: cache
---
kind: pipeline
name: mysql

platform:
  os: linux
  arch: arm64

steps:
- commands:
  - cp -rn example/checks test/int_test/mysql
  - cp -rn example/load_data test/int_test/mysql
  - cp -rn example/run_sql test/int_test/mysql
  - cp -rn example/lookups test/int_test/mysql
  - cp -rn example/fake test/int_test/mysql
  - poetry install -E mysql
  - cd test/int_test/mysql
  - poetry run data_check ping --wait --timeout 60 --retry 5
  - rm -f checks/pipelines/fake_data/main.simple_fake_table.csv
  - rm -f checks/pipelines/fake_data/main.simple_fake_table_2.csv
  - rm -f checks/generated/data_with_hash.csv
  - rm -f test.db
  - poetry run data_check sql --workers 1 --files prepare
  - poetry run pytest ../test_int_tests.py
  - poetry run pytest ../../../test/database
  environment:
    DB_CONNECTION:
      from_secret: MYSQL_CONNECTION
    DB_PASSWORD:
      from_secret: MYSQL_PASSWORD
    DB_USER:
      from_secret: MYSQL_USER
  image: local/poetry:3.8
  name: data_check
  pull: if-not-exists
  volumes:
  - name: cache
    path: /root/.cache
type: docker
volumes:
- host:
    path: /tmp/data_check_cache
  name: cache
---
kind: pipeline
name: postgres

platform:
  os: linux
  arch: arm64

steps:
- commands:
  - cp -rn example/checks test/int_test/postgres
  - cp -rn example/load_data test/int_test/postgres
  - cp -rn example/run_sql test/int_test/postgres
  - cp -rn example/lookups test/int_test/postgres
  - cp -rn example/fake test/int_test/postgres
  - poetry install -E postgres
  - cd test/int_test/postgres
  - poetry run data_check ping --wait --timeout 60 --retry 5
  - rm -f checks/pipelines/fake_data/main.simple_fake_table.csv
  - rm -f checks/pipelines/fake_data/main.simple_fake_table_2.csv
  - rm -f checks/generated/data_with_hash.csv
  - rm -f test.db
  - poetry run data_check sql --workers 1 --files prepare
  - poetry run pytest ../test_int_tests.py
  - poetry run pytest ../../../test/database
  environment:
    DB_CONNECTION:
      from_secret: POSTGRES_CONNECTION
    DB_PASSWORD:
      from_secret: POSTGRES_PASSWORD
    DB_USER:
      from_secret: POSTGRES_USER
  image: local/poetry:3.8
  name: data_check
  pull: if-not-exists
  volumes:
  - name: cache
    path: /root/.cache
type: docker
volumes:
- host:
    path: /tmp/data_check_cache
  name: cache
---
kind: pipeline
name: mssql
steps:
- commands:
  - cp -rn example/checks test/int_test/mssql
  - cp -rn example/load_data test/int_test/mssql
  - cp -rn example/run_sql test/int_test/mssql
  - cp -rn example/lookups test/int_test/mssql
  - cp -rn example/fake test/int_test/mssql
  - poetry install -E mssql
  - cd test/int_test/mssql
  - poetry run data_check ping --wait --timeout 60 --retry 5
  - rm -f checks/pipelines/fake_data/main.simple_fake_table.csv
  - rm -f checks/pipelines/fake_data/main.simple_fake_table_2.csv
  - rm -f checks/generated/data_with_hash.csv
  - rm -f test.db
  - poetry run data_check sql --workers 1 --files prepare
  - poetry run pytest ../test_int_tests.py
  - poetry run pytest ../../../test/database
  environment:
    DB_CONNECTION:
      from_secret: MSSQL_CONNECTION
    DB_PASSWORD:
      from_secret: MSSQL_PASSWORD
    DB_USER:
      from_secret: MSSQL_USER
  image: local/poetry_mssql
  name: data_check
  pull: if-not-exists
  volumes:
  - name: cache
    path: /root/.cache
type: docker
volumes:
- host:
    path: /tmp/data_check_cache
  name: cache
